{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUOSATwSwQU_",
        "outputId": "f2add67c-70ef-41cd-e713-145a026b1df4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.4.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import MNISTSuperpixels\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch_geometric.nn import GATConv"
      ],
      "metadata": {
        "id": "rqMGlIUnwLJh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MNISTSuperpixels(root='data/MNIST', train=True)\n",
        "test_dataset = MNISTSuperpixels(root='data/MNIST', train=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1Cty8ExwU7g",
        "outputId": "7747a04d-38b8-483f-e9fc-0d65716643ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting data/MNIST/raw/MNISTSuperpixels.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a06oLIdRZr-i",
        "outputId": "d101379e-f634-4955-880f-ed5a7ba2c8d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[75, 1], edge_index=[2, 1399], y=[1], pos=[75, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_func(original_batch: list[Data]):\n",
        "    batch_node_features: list[torch.Tensor] = []\n",
        "    batch_edge_indices: list[torch.Tensor] = []\n",
        "    classes: list[int] = []\n",
        "\n",
        "    for data in original_batch:\n",
        "        node_features = torch.cat((data.x, data.pos), dim=-1).to(device)\n",
        "        edge_indices = data.edge_index.to(device)\n",
        "        class_ = int(data.y)\n",
        "\n",
        "        batch_node_features.append(node_features)\n",
        "        batch_edge_indices.append(edge_indices)\n",
        "        classes.append(class_)\n",
        "\n",
        "    collated = {\n",
        "        \"batch_node_features\": batch_node_features,\n",
        "        \"batch_edge_indices\": batch_edge_indices,\n",
        "        \"classes\": torch.LongTensor(classes).to(device),\n",
        "    }\n",
        "\n",
        "    return collated"
      ],
      "metadata": {
        "id": "0z8M2O5KZhrW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 600\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                          collate_fn=collate_func)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False,\n",
        "                        collate_fn=collate_func)"
      ],
      "metadata": {
        "id": "kiAywlK9Zf0e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      in_channels = 3,\n",
        "      hidden_dim = 152,\n",
        "      num_classes = 10,\n",
        "  ):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.num_classes = num_classes\n",
        "\n",
        "    self.conv1 = GATConv(in_channels=in_channels, out_channels=hidden_dim)\n",
        "    self.conv2 = GATConv(in_channels=hidden_dim, out_channels=hidden_dim)\n",
        "    self.conv3 = GATConv(in_channels=hidden_dim, out_channels=hidden_dim)\n",
        "    self.conv4 = GATConv(in_channels=hidden_dim, out_channels=hidden_dim)\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(in_channels+4*hidden_dim, 256),\n",
        "        nn.ReLU(True),\n",
        "        nn.Linear(256, 128),\n",
        "        nn.ReLU(True),\n",
        "        nn.Linear(128, num_classes),\n",
        "    )\n",
        "\n",
        "  def forward_one_base(self, node_features: torch.Tensor, edge_indices: torch.Tensor) -> torch.Tensor:\n",
        "    assert node_features.ndim == 2 and node_features.shape[1] == self.in_channels\n",
        "    assert edge_indices.ndim == 2 and edge_indices.shape[0] == 2\n",
        "\n",
        "    x = node_features\n",
        "    x1 = self.conv1(x, edge_indices)\n",
        "    x2 = self.conv2(x1, edge_indices)\n",
        "    x3 = self.conv3(x2, edge_indices)\n",
        "    x4 = self.conv4(x3, edge_indices)\n",
        "\n",
        "    x_cat = torch.cat((x, x1, x2, x3, x4), dim=-1)\n",
        "\n",
        "    x_cat = x_cat.view(x_cat.size(0), -1)\n",
        "    return x_cat\n",
        "\n",
        "  def forward(self, batch_node_features: list[torch.Tensor], batch_edge_indices: list[torch.Tensor]) -> torch.Tensor:\n",
        "    assert len(batch_node_features) == len(batch_edge_indices)\n",
        "\n",
        "    features_list = []\n",
        "    for node_features, edge_indices in zip(batch_node_features, batch_edge_indices):\n",
        "      features_list.append(self.forward_one_base(node_features=node_features, edge_indices=edge_indices))\n",
        "\n",
        "    features = torch.stack(features_list, dim=0)  # BATCH_SIZE x NUM_NODES x NUM_FEATURES\n",
        "    features = features.mean(dim=1)  # readout operation [BATCH_SIZE x NUM_FEATURES]\n",
        "\n",
        "    logits = self.fc(features)\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "3p7BJhDew_cP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "90tbqUGAz14g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GNN(in_channels=3, hidden_dim=64).to(device)"
      ],
      "metadata": {
        "id": "rJOpdFmcs5Ce"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQUH1ivpbjjt",
        "outputId": "1aa74722-cd55-4cff-9339-4f08854e8669"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GNN(\n",
              "  (conv1): GATConv(3, 64, heads=1)\n",
              "  (conv2): GATConv(64, 64, heads=1)\n",
              "  (conv3): GATConv(64, 64, heads=1)\n",
              "  (conv4): GATConv(64, 64, heads=1)\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=259, out_features=256, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "V1jzNN1As_uf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, criterion, batches_passed):\n",
        "  model.train()\n",
        "  total_loss=0\n",
        "  total_correct=0\n",
        "  total_samples=0\n",
        "\n",
        "  for batch in enumerate(loader):\n",
        "    batch_node_features = batch[\"batch_node_features\"]\n",
        "    batch_edge_indices = batch[\"batch_edge_indices\"]\n",
        "    classes = batch[\"classes\"]\n",
        "\n",
        "    logits = model(batch_node_features=batch_node_features, batch_edge_indices=batch_edge_indices)\n",
        "    predicted_classes = torch.argmax(logits, dim=1)\n",
        "\n",
        "    #loss = criterion(logits, classes).mean()\n",
        "    loss = criterion(logits, classes)\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #accuracy = (predicted_classes == classes).to(torch.float32).mean()\n",
        "    correct = (predicted_classes == classes).sum().item()\n",
        "    total_correct += correct\n",
        "    total_samples += len(classes)\n",
        "\n",
        "    '''print('Training accuracy: ',accuracy)\n",
        "    print('Training loss: ',loss)\n",
        "    print('Batch: ',batches_passed)'''\n",
        "\n",
        "    batches_passed += 1\n",
        "\n",
        "    #if i+1>num_batches:\n",
        "     # break\n",
        "  epoch_loss=total_loss / len(loader)\n",
        "  epoch_accuracy = total_correct / total_samples\n",
        "\n",
        "  print(f\"Epoch [{batches_passed}], Train Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
        "  return batches_passed"
      ],
      "metadata": {
        "id": "3lKdfQREyo1v"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, epochs):\n",
        "  model.eval()\n",
        "  accu=0.0\n",
        "  samp=0.0\n",
        "  total_correct=0\n",
        "  total_samples=0\n",
        "\n",
        "  for batch in loader:\n",
        "    batch_node_features = batch[\"batch_node_features\"]\n",
        "    batch_edge_indices = batch[\"batch_edge_indices\"]\n",
        "    classes = batch[\"classes\"]\n",
        "\n",
        "    logits = model(batch_node_features=batch_node_features, batch_edge_indices=batch_edge_indices)\n",
        "    predicted_classes = torch.argmax(logits, dim=1)\n",
        "\n",
        "    '''accu += float((predicted_classes == classes).to(torch.float32).mean().cpu().numpy()) * len(classes)\n",
        "    samp += len(classes)'''\n",
        "    correct = (predicted_classes == classes).sum().item()\n",
        "    total_correct += correct\n",
        "    total_samples += len(classes)\n",
        "\n",
        "  #accuracy = accu/samp\n",
        "  epoch_accuracy = total_correct / total_samples\n",
        "  print(f\"Validation Accuracy after epoch [{epochs}]: {epoch_accuracy:.3f}\")\n",
        "\n",
        "\n",
        "  print(\"Accuracy: \", accu)"
      ],
      "metadata": {
        "id": "lZ6Sqdb-zuhR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batches_passed = 0\n",
        "epochs=3\n",
        "\n",
        "for epoc in range(epochs):\n",
        "  print(f\"Epoch [{epoc + 1}/{epochs}]\")\n",
        "  batches_passed = train(\n",
        "      model=model,\n",
        "      optimizer=optimizer,\n",
        "      loader=train_loader,\n",
        "      criterion=criterion,\n",
        "      batches_passed=batches_passed,\n",
        "      )\n",
        "\n",
        "  evaluate(\n",
        "      model=model,\n",
        "      loader=test_loader,\n",
        "      epochs=epoc + 1,\n",
        "      )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "731_z05KtUQv",
        "outputId": "4e8e9022-b31c-43fe-883e-634032d2ddf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-2c3b02930ff1>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch [{epoc + 1}/{epochs}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   batches_passed = train(\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-01d34b59fab4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, criterion, batches_passed)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"classes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_node_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_node_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_edge_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_edge_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mpredicted_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-f54eca6d42d1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch_node_features, batch_edge_indices)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mfeatures_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_indices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_node_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_edge_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m       \u001b[0mfeatures_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_one_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# BATCH_SIZE x NUM_NODES x NUM_FEATURES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-f54eca6d42d1>\u001b[0m in \u001b[0;36mforward_one_base\u001b[0;34m(self, node_features, edge_indices)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;31m# edge_updater_type: (alpha: OptPairTensor, edge_attr: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         alpha = self.edge_updater(edge_index, alpha=alpha, edge_attr=edge_attr,\n\u001b[0m\u001b[1;32m    338\u001b[0m                                   size=size)\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/torch_geometric.nn.conv.gat_conv_GATConv_edge_updater_btxm4s9i.py\u001b[0m in \u001b[0;36medge_updater\u001b[0;34m(self, edge_index, alpha, edge_attr, size)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;31m# End Edge Update Forward Pre Hook #########################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     out = self.edge_update(\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0malpha_j\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_j\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0malpha_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36medge_update\u001b[0;34m(self, alpha_j, alpha_i, edge_attr, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/_softmax.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(src, index, ptr, num_nodes, dim)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0msrc_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msrc_max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mout_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mout_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, 4,8)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvMhdnpPnH4o",
        "outputId": "c043752c-f33a-44d3-9cc1-aa51b434cd06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy:  tensor(0.1406)\n",
            "Training loss:  tensor(2.3268, grad_fn=<MeanBackward0>)\n",
            "Batch:  4\n",
            "Training accuracy:  tensor(0.0625)\n",
            "Training loss:  tensor(2.3515, grad_fn=<MeanBackward0>)\n",
            "Batch:  5\n",
            "Training accuracy:  tensor(0.0781)\n",
            "Training loss:  tensor(2.3663, grad_fn=<MeanBackward0>)\n",
            "Batch:  6\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.3250, grad_fn=<MeanBackward0>)\n",
            "Batch:  7\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3463, grad_fn=<MeanBackward0>)\n",
            "Batch:  8\n",
            "Training accuracy:  tensor(0.0312)\n",
            "Training loss:  tensor(2.3540, grad_fn=<MeanBackward0>)\n",
            "Batch:  9\n",
            "Training accuracy:  tensor(0.1250)\n",
            "Training loss:  tensor(2.2509, grad_fn=<MeanBackward0>)\n",
            "Batch:  10\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.3201, grad_fn=<MeanBackward0>)\n",
            "Batch:  11\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3267, grad_fn=<MeanBackward0>)\n",
            "Batch:  12\n",
            "Epoch 1/10, Train Loss: 13.000\n",
            "Training accuracy:  tensor(0.1562)\n",
            "Training loss:  tensor(2.3614, grad_fn=<MeanBackward0>)\n",
            "Batch:  4\n",
            "Training accuracy:  tensor(0.0469)\n",
            "Training loss:  tensor(2.3846, grad_fn=<MeanBackward0>)\n",
            "Batch:  5\n",
            "Training accuracy:  tensor(0.0781)\n",
            "Training loss:  tensor(2.3674, grad_fn=<MeanBackward0>)\n",
            "Batch:  6\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.2979, grad_fn=<MeanBackward0>)\n",
            "Batch:  7\n",
            "Training accuracy:  tensor(0.1250)\n",
            "Training loss:  tensor(2.3065, grad_fn=<MeanBackward0>)\n",
            "Batch:  8\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.3414, grad_fn=<MeanBackward0>)\n",
            "Batch:  9\n",
            "Training accuracy:  tensor(0.0781)\n",
            "Training loss:  tensor(2.3869, grad_fn=<MeanBackward0>)\n",
            "Batch:  10\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.3463, grad_fn=<MeanBackward0>)\n",
            "Batch:  11\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3004, grad_fn=<MeanBackward0>)\n",
            "Batch:  12\n",
            "Epoch 2/10, Train Loss: 13.000\n",
            "Training accuracy:  tensor(0.0312)\n",
            "Training loss:  tensor(2.3365, grad_fn=<MeanBackward0>)\n",
            "Batch:  4\n",
            "Training accuracy:  tensor(0.0781)\n",
            "Training loss:  tensor(2.3288, grad_fn=<MeanBackward0>)\n",
            "Batch:  5\n",
            "Training accuracy:  tensor(0.1406)\n",
            "Training loss:  tensor(2.3116, grad_fn=<MeanBackward0>)\n",
            "Batch:  6\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.2955, grad_fn=<MeanBackward0>)\n",
            "Batch:  7\n",
            "Training accuracy:  tensor(0.0312)\n",
            "Training loss:  tensor(2.4220, grad_fn=<MeanBackward0>)\n",
            "Batch:  8\n",
            "Training accuracy:  tensor(0.0625)\n",
            "Training loss:  tensor(2.3471, grad_fn=<MeanBackward0>)\n",
            "Batch:  9\n",
            "Training accuracy:  tensor(0.1250)\n",
            "Training loss:  tensor(2.3152, grad_fn=<MeanBackward0>)\n",
            "Batch:  10\n",
            "Training accuracy:  tensor(0.0625)\n",
            "Training loss:  tensor(2.3324, grad_fn=<MeanBackward0>)\n",
            "Batch:  11\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3191, grad_fn=<MeanBackward0>)\n",
            "Batch:  12\n",
            "Epoch 3/10, Train Loss: 13.000\n",
            "Training accuracy:  tensor(0.1250)\n",
            "Training loss:  tensor(2.3410, grad_fn=<MeanBackward0>)\n",
            "Batch:  4\n",
            "Training accuracy:  tensor(0.1406)\n",
            "Training loss:  tensor(2.3255, grad_fn=<MeanBackward0>)\n",
            "Batch:  5\n",
            "Training accuracy:  tensor(0.1250)\n",
            "Training loss:  tensor(2.3083, grad_fn=<MeanBackward0>)\n",
            "Batch:  6\n",
            "Training accuracy:  tensor(0.0781)\n",
            "Training loss:  tensor(2.3249, grad_fn=<MeanBackward0>)\n",
            "Batch:  7\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.2842, grad_fn=<MeanBackward0>)\n",
            "Batch:  8\n",
            "Training accuracy:  tensor(0.1719)\n",
            "Training loss:  tensor(2.3285, grad_fn=<MeanBackward0>)\n",
            "Batch:  9\n",
            "Training accuracy:  tensor(0.0469)\n",
            "Training loss:  tensor(2.3587, grad_fn=<MeanBackward0>)\n",
            "Batch:  10\n",
            "Training accuracy:  tensor(0.1719)\n",
            "Training loss:  tensor(2.2634, grad_fn=<MeanBackward0>)\n",
            "Batch:  11\n",
            "Training accuracy:  tensor(0.1250)\n",
            "Training loss:  tensor(2.3295, grad_fn=<MeanBackward0>)\n",
            "Batch:  12\n",
            "Epoch 4/10, Train Loss: 13.000\n",
            "Training accuracy:  tensor(0.2188)\n",
            "Training loss:  tensor(2.2626, grad_fn=<MeanBackward0>)\n",
            "Batch:  4\n",
            "Training accuracy:  tensor(0.1250)\n",
            "Training loss:  tensor(2.2745, grad_fn=<MeanBackward0>)\n",
            "Batch:  5\n",
            "Training accuracy:  tensor(0.0469)\n",
            "Training loss:  tensor(2.3671, grad_fn=<MeanBackward0>)\n",
            "Batch:  6\n",
            "Training accuracy:  tensor(0.0625)\n",
            "Training loss:  tensor(2.3520, grad_fn=<MeanBackward0>)\n",
            "Batch:  7\n",
            "Training accuracy:  tensor(0.1406)\n",
            "Training loss:  tensor(2.3120, grad_fn=<MeanBackward0>)\n",
            "Batch:  8\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3325, grad_fn=<MeanBackward0>)\n",
            "Batch:  9\n",
            "Training accuracy:  tensor(0.1406)\n",
            "Training loss:  tensor(2.3666, grad_fn=<MeanBackward0>)\n",
            "Batch:  10\n",
            "Training accuracy:  tensor(0.1875)\n",
            "Training loss:  tensor(2.3296, grad_fn=<MeanBackward0>)\n",
            "Batch:  11\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3544, grad_fn=<MeanBackward0>)\n",
            "Batch:  12\n",
            "Epoch 5/10, Train Loss: 13.000\n",
            "Training accuracy:  tensor(0.1250)\n",
            "Training loss:  tensor(2.3103, grad_fn=<MeanBackward0>)\n",
            "Batch:  4\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3285, grad_fn=<MeanBackward0>)\n",
            "Batch:  5\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3471, grad_fn=<MeanBackward0>)\n",
            "Batch:  6\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.3575, grad_fn=<MeanBackward0>)\n",
            "Batch:  7\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3532, grad_fn=<MeanBackward0>)\n",
            "Batch:  8\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3428, grad_fn=<MeanBackward0>)\n",
            "Batch:  9\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3679, grad_fn=<MeanBackward0>)\n",
            "Batch:  10\n",
            "Training accuracy:  tensor(0.1406)\n",
            "Training loss:  tensor(2.3051, grad_fn=<MeanBackward0>)\n",
            "Batch:  11\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3072, grad_fn=<MeanBackward0>)\n",
            "Batch:  12\n",
            "Epoch 6/10, Train Loss: 13.000\n",
            "Training accuracy:  tensor(0.0625)\n",
            "Training loss:  tensor(2.3616, grad_fn=<MeanBackward0>)\n",
            "Batch:  4\n",
            "Training accuracy:  tensor(0.1250)\n",
            "Training loss:  tensor(2.3223, grad_fn=<MeanBackward0>)\n",
            "Batch:  5\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3398, grad_fn=<MeanBackward0>)\n",
            "Batch:  6\n",
            "Training accuracy:  tensor(0.1406)\n",
            "Training loss:  tensor(2.3107, grad_fn=<MeanBackward0>)\n",
            "Batch:  7\n",
            "Training accuracy:  tensor(0.1562)\n",
            "Training loss:  tensor(2.2935, grad_fn=<MeanBackward0>)\n",
            "Batch:  8\n",
            "Training accuracy:  tensor(0.1250)\n",
            "Training loss:  tensor(2.3633, grad_fn=<MeanBackward0>)\n",
            "Batch:  9\n",
            "Training accuracy:  tensor(0.1719)\n",
            "Training loss:  tensor(2.2689, grad_fn=<MeanBackward0>)\n",
            "Batch:  10\n",
            "Training accuracy:  tensor(0.0781)\n",
            "Training loss:  tensor(2.3780, grad_fn=<MeanBackward0>)\n",
            "Batch:  11\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.2930, grad_fn=<MeanBackward0>)\n",
            "Batch:  12\n",
            "Epoch 7/10, Train Loss: 13.000\n",
            "Training accuracy:  tensor(0.0781)\n",
            "Training loss:  tensor(2.3476, grad_fn=<MeanBackward0>)\n",
            "Batch:  4\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3168, grad_fn=<MeanBackward0>)\n",
            "Batch:  5\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.3437, grad_fn=<MeanBackward0>)\n",
            "Batch:  6\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3848, grad_fn=<MeanBackward0>)\n",
            "Batch:  7\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.3230, grad_fn=<MeanBackward0>)\n",
            "Batch:  8\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.3411, grad_fn=<MeanBackward0>)\n",
            "Batch:  9\n",
            "Training accuracy:  tensor(0.1719)\n",
            "Training loss:  tensor(2.2772, grad_fn=<MeanBackward0>)\n",
            "Batch:  10\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.3418, grad_fn=<MeanBackward0>)\n",
            "Batch:  11\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.3355, grad_fn=<MeanBackward0>)\n",
            "Batch:  12\n",
            "Epoch 8/10, Train Loss: 13.000\n",
            "Training accuracy:  tensor(0.0781)\n",
            "Training loss:  tensor(2.3183, grad_fn=<MeanBackward0>)\n",
            "Batch:  4\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.2988, grad_fn=<MeanBackward0>)\n",
            "Batch:  5\n",
            "Training accuracy:  tensor(0.1250)\n",
            "Training loss:  tensor(2.3159, grad_fn=<MeanBackward0>)\n",
            "Batch:  6\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.3188, grad_fn=<MeanBackward0>)\n",
            "Batch:  7\n",
            "Training accuracy:  tensor(0.0781)\n",
            "Training loss:  tensor(2.3183, grad_fn=<MeanBackward0>)\n",
            "Batch:  8\n",
            "Training accuracy:  tensor(0.0312)\n",
            "Training loss:  tensor(2.3406, grad_fn=<MeanBackward0>)\n",
            "Batch:  9\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.3379, grad_fn=<MeanBackward0>)\n",
            "Batch:  10\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3228, grad_fn=<MeanBackward0>)\n",
            "Batch:  11\n",
            "Training accuracy:  tensor(0.0625)\n",
            "Training loss:  tensor(2.3226, grad_fn=<MeanBackward0>)\n",
            "Batch:  12\n",
            "Epoch 9/10, Train Loss: 13.000\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.2989, grad_fn=<MeanBackward0>)\n",
            "Batch:  4\n",
            "Training accuracy:  tensor(0.0781)\n",
            "Training loss:  tensor(2.3926, grad_fn=<MeanBackward0>)\n",
            "Batch:  5\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.2889, grad_fn=<MeanBackward0>)\n",
            "Batch:  6\n",
            "Training accuracy:  tensor(0.1719)\n",
            "Training loss:  tensor(2.3143, grad_fn=<MeanBackward0>)\n",
            "Batch:  7\n",
            "Training accuracy:  tensor(0.0625)\n",
            "Training loss:  tensor(2.3048, grad_fn=<MeanBackward0>)\n",
            "Batch:  8\n",
            "Training accuracy:  tensor(0.1094)\n",
            "Training loss:  tensor(2.3162, grad_fn=<MeanBackward0>)\n",
            "Batch:  9\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.3331, grad_fn=<MeanBackward0>)\n",
            "Batch:  10\n",
            "Training accuracy:  tensor(0.0938)\n",
            "Training loss:  tensor(2.2902, grad_fn=<MeanBackward0>)\n",
            "Batch:  11\n",
            "Training accuracy:  tensor(0.0781)\n",
            "Training loss:  tensor(2.3856, grad_fn=<MeanBackward0>)\n",
            "Batch:  12\n",
            "Epoch 10/10, Train Loss: 13.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameter tuning\n",
        "batch_size = 4\n",
        "epochs = 2\n",
        "hidden_dim = 64\n",
        "optimizer1 = torch.optim.Adam(model.parameters(), lr=0.0001) #lr=0.0001\n",
        "train(model, train_loader, optimizer1, criterion, 3)"
      ],
      "metadata": {
        "id": "bcVjjKbHv8ox"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#secodn\n",
        "batch_size = 8 #changed\n",
        "epochs = 2\n",
        "hidden_dim = 164 #changed\n",
        "lr = 0.002\n",
        "optimizer2 = torch.optim.Adam(model.parameters(), lr=0.002) #lr=0.002\n",
        "train(model, train_loader, optimizer2, criterion, 3)"
      ],
      "metadata": {
        "id": "HgeBJas_IbvC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib as plt\n",
        "\n",
        "\n",
        "def visualize_graphs(data_loader, num_samples=5):\n",
        "    for i in range(10):\n",
        "        print(f\"Class: {i}\")\n",
        "        class_indices = [idx for idx, data in enumerate(data_loader.dataset) if data.y == i]\n",
        "        sample_indices = class_indices[:num_samples]\n",
        "        for idx in sample_indices:\n",
        "            data = data_loader.dataset[idx]\n",
        "            edge_index = data.edge_index.cpu().numpy()\n",
        "            G = nx.Graph()\n",
        "            G.add_edges_from(edge_index.T)\n",
        "            plt.figure()\n",
        "            nx.draw(G, with_labels=True)\n",
        "            plt.title(f\"Sample {idx} from class {i}\")\n",
        "            plt.show()\n"
      ],
      "metadata": {
        "id": "gznqkQDgIzc8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_graphs(test_loader)"
      ],
      "metadata": {
        "id": "82ffub67Jqgs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN model\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = x.view(-1, 32 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "v5rEs7AMJsoA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn = CNNModel()\n",
        "\n",
        "criterion_cnn = nn.CrossEntropyLoss()\n",
        "optimizer_cnn = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "VKPBZ-iwJ-QS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loaderr = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loaderr = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pok4B6pLZtj",
        "outputId": "53d1b7cb-e548-46a0-f860-49e382d5f180"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 103197289.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 80169221.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 32205883.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 13715283.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, test_loader, num_epochs=5):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(train_loader, 0):  # Modified this line\n",
        "            optimizer_cnn.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion_cnn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer_cnn.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "        # Validate the model\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in test_loader:\n",
        "                inputs, labels = data\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print(f\"Accuracy on test set: {100 * correct / total}%\")\n"
      ],
      "metadata": {
        "id": "x8cYWJvzKJHL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model_cnn, train_loaderr, test_loaderr, num_epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upksRmA1KLHK",
        "outputId": "a0166d22-6977-4833-d27b-92da87cbc80c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 2.30235404602246\n",
            "Accuracy on test set: 8.73%\n"
          ]
        }
      ]
    }
  ]
}