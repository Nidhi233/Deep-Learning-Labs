{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dTaTKuDd1PUY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading dataset\n",
        "dataset = datasets.SVHN(root=\"data\", download=True, transform=ToTensor())\n",
        "test_svhn = datasets.SVHN(root=\"data\", split=\"test\", download=True, transform=ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjjnVt_h6zqJ",
        "outputId": "a6955343-3467-4c37-b0d7-7fa4cc379b5f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: data/train_32x32.mat\n",
            "Using downloaded and verified file: data/test_32x32.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(dataset, batch_size=384, shuffle=True)"
      ],
      "metadata": {
        "id": "Ux_bc59awgvF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "E1iesq4661ZU",
        "outputId": "bc7adefd-d127-4d20-deee-107fef1a1c11"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.svhn.SVHN"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torchvision.datasets.svhn.SVHN</b><br/>def __init__(root: str, split: str=&#x27;train&#x27;, transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torchvision/datasets/svhn.py</a>`SVHN &lt;http://ufldl.stanford.edu/housenumbers/&gt;`_ Dataset.\n",
              "Note: The SVHN dataset assigns the label `10` to the digit `0`. However, in this Dataset,\n",
              "we assign the label `0` to the digit `0` to be compatible with PyTorch loss functions which\n",
              "expect the class labels to be in the range `[0, C-1]`\n",
              "\n",
              ".. warning::\n",
              "\n",
              "    This class needs `scipy &lt;https://docs.scipy.org/doc/&gt;`_ to load data from `.mat` format.\n",
              "\n",
              "Args:\n",
              "    root (string): Root directory of the dataset where the data is stored.\n",
              "    split (string): One of {&#x27;train&#x27;, &#x27;test&#x27;, &#x27;extra&#x27;}.\n",
              "        Accordingly dataset is selected. &#x27;extra&#x27; is Extra training set.\n",
              "    transform (callable, optional): A function/transform that  takes in an PIL image\n",
              "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
              "    target_transform (callable, optional): A function/transform that takes in the\n",
              "        target and transforms it.\n",
              "    download (bool, optional): If true, downloads the dataset from the internet and\n",
              "        puts it in root directory. If dataset is already downloaded, it is not\n",
              "        downloaded again.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 11);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(168, 448, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(448),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(448, 256, 4, 2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, padding=1, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, padding=1, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, padding=1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers1(x)\n"
      ],
      "metadata": {
        "id": "Ya7GsUH76-d4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers2 = nn.Sequential(\n",
        "        nn.Conv2d(1, 256, 4, 2, 1, bias=False),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        nn.Conv2d(512, 1024, 3, 2, 0, bias=False),\n",
        "        nn.BatchNorm2d(1024),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        nn.Conv2d(1024, 1, 3, 1, 0, bias=False),\n",
        "    )\n",
        "\n",
        "    def _weight_init(self):\n",
        "      for p in self.modules():\n",
        "        if isinstance(p,nn.Conv2d):\n",
        "          nn.init.normal_(p.weight, mean=0, std=0.02)\n",
        "        elif isinstance(p,nn.BatchNorm2d):\n",
        "          nn.init.normal_(p.weight, mean=1.0, std=0.02)\n",
        "          nn.init.constant_(p.bias, 0)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x=self.layers2(x)\n",
        "      x=x.view(x.shape[0], -1)\n",
        "      return x"
      ],
      "metadata": {
        "id": "W8KfvucWpSzk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.implementing min_max loss as described in GAN paper\n",
        "#3.modifying the loss function(Least square) as per LS-GAN paper\n",
        "#difference in both this type is in discriminator loss where, usual-GAN has BCELoss while LSGAN has MSELoss\n",
        "#generator loss remains the same, and min_max_loss = discr_loss, gen_loss in both the cases\n",
        "\n",
        "def discriminator_loss(real,fake,loss_type='GAN'):\n",
        "  if loss_type == 'GAN':\n",
        "    criterion = nn.BCELoss(with_logits=True) #2nd part\n",
        "  else:\n",
        "    criterion = nn.MSELoss() #3rd part\n",
        "\n",
        "  real_loss = criterion(real,torch.ones_like(real))\n",
        "  fake_loss = criterion(fake,torch.zeros_like(fake))\n",
        "\n",
        "  return real_loss+fake_loss\n",
        "\n",
        "def generator_loss(fake):\n",
        "  criterion = nn.BCELoss(with_logits=True)\n",
        "  return criterion(fake,torch.ones_like(fake))\n"
      ],
      "metadata": {
        "id": "EorseXs4DmGS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters\n",
        "learning_rate = 0.001\n",
        "epochs = 4"
      ],
      "metadata": {
        "id": "PxH_GsQiGEs4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images in loader:\n",
        "  print(images[0].shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJCbb0VT5aTm",
        "outputId": "0d9b892a-2433-4a6b-83b6-bf29f4ec2d1e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([384, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#noise_size = 168*448*2*1 # Example noise vector size, adjust as needed\n",
        "noise = torch.randn(384*168*448*2).reshape(384,168,448,2)\n",
        "noise.shape  # Random noise with normal distribution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxXgJBCv4PNs",
        "outputId": "8794940f-c2da-4896-9b25-963356942446"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([384, 168, 448, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#initializing model and optimizers -- for part 2\n",
        "discriminator = Discriminator()\n",
        "generator = Generator()\n",
        "\n",
        "discr_opti = torch.optim.Adam(discriminator.parameters(),lr=learning_rate)\n",
        "gen_opti = torch.optim.Adam(generator.parameters(),lr=learning_rate)\n",
        "\n",
        "#4.training on BCE loss -- for part 2\n",
        "for epoch in range(epochs):\n",
        "  for i, dataset in enumerate(loader):\n",
        "    #training discriminator to distinguish between real and fake\n",
        "    discr_opti.zero_grad()\n",
        "    real_data = dataset\n",
        "    fake_data = generator(noise)\n",
        "\n",
        "    real = discriminator(real_data)\n",
        "    fake = discriminator(fake_data.detach())\n",
        "\n",
        "    discr_loss = discriminator_loss(real,fake,loss_type='GAN')\n",
        "    discr_loss.backward()\n",
        "    discr_opti.step()\n",
        "\n",
        "    #training generator to generate fake images close to real ones\n",
        "    gen_opti.zero_grad()\n",
        "    fake_data = generator(noise)\n",
        "    fake = discriminator(fake_data)\n",
        "\n",
        "    gen_loss = generator_loss(fake)\n",
        "    gen_loss.backward()\n",
        "    gen_opti.step()\n",
        "\n",
        "    if i%100 == 0:\n",
        "      print(f\"[{epoch}/{epochs}][{i}/{len(loader)}]\" f\"D_Loss: {discr_loss.item():.3f}, G_Loss: {gen_loss.item():.3f}\")"
      ],
      "metadata": {
        "id": "Agi6mQrpF4ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    fake_images = generator(torch.randn(64, , 1, 1))\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Generated Images\")\n",
        "plt.imshow(np.transpose(torchvision.utils.make_grid(fake_images, padding=2, normalize=True).cpu(), (1, 2, 0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DJIb67y9yOva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initializing model and optimizers -- part 3\n",
        "discriminator2 = Discriminator()\n",
        "generator2 = Generator()\n",
        "\n",
        "discr_opti2 = torch.optim.Adam(discriminator2.parameters(),lr=learning_rate)\n",
        "gen_opti2 = torch.optim.Adam(generator2.parameters(),lr=learning_rate)\n",
        "\n",
        "#4.training on MSE loss -- for part 3\n",
        "for epoch in range(epochs):\n",
        "  for i, dataset in enumerate(loader):\n",
        "    #training discriminator2 to distinguish between real and fake\n",
        "    discr_opti2.zero_grad()\n",
        "    real_data = dataset\n",
        "    fake_data = generator2(noise)\n",
        "\n",
        "    real = discriminator2(real_data)\n",
        "    fake = discriminator2(fake_data.detach())\n",
        "\n",
        "    discr_loss = discriminator2(real,fake,loss_type='LSGAN')\n",
        "    discr_loss.backward()\n",
        "    discr_opti2.step()\n",
        "\n",
        "    #training generator2 to generate fake images close to real ones\n",
        "    gen_opti2.zero_grad()\n",
        "    fake_data = generator2(noise)\n",
        "    fake = discriminator2(fake_data)\n",
        "\n",
        "    gen_loss = generator2(fake)\n",
        "    gen_loss.backward()\n",
        "    gen_opti2.step()\n",
        "\n",
        "    if i%100 == 0:\n",
        "      print(f\"[{epoch}/{epochs}][{i}/{len(loader)}]\" f\"D_Loss: {discr_loss.item():.3f}, G_Loss: {gen_loss.item():.3f}\")"
      ],
      "metadata": {
        "id": "awaqHowsxPmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    fake_images = generator2(torch.randn(64, 100, 1, 1))\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Generated Images\")\n",
        "plt.imshow(np.transpose(torchvision.utils.make_grid(fake_images, padding=2, normalize=True).cpu(), (1, 2, 0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E1rBMyef5fbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tried to visualize and generate images for both the parts\n",
        "#but although my code is running, it keeps on crashing due to RAM usage issue and is unable to train and move forward\n",
        "#as per my knowledge though, I tried to code task parts - 1,2,3,4 as mentioned in the lab"
      ],
      "metadata": {
        "id": "jbWtUS_F3A03"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}